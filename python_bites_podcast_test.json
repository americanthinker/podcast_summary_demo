{"podcast_details": {"podcast_title": "Python Bytes", "episode_title": "#347 The One About Context Mangers", "episode_image": "https://pythonbytes.fm/static/img/podcast-theme-img_1400.webp", "episode_transcript": " Hello and welcome to Python Bites where we deliver Python news and headlines directly to your earbuds. This is episode 347 recorded August 8th, 2023. And I'm Brian Ocken. And I'm Michael Kennedy. Well, we have lots of great topics today. I'm pretty excited to get to them. We this episode of course is well, not of course, but is sponsored by us. So if you'd like to support the show, you can support us on Patreon or check out one of Michael's many courses or my other podcasts or you know how to support us. So they know the deal. Brian, let me throw one more in there for people. Okay. If you work for a company and that company is trying to spread the word about a product or service, Python Bites dot fm slash sponsor and check that as well. Recommend that to their marketing team. Definitely. And if you are listening and would like to join the show live sometimes, just check out Python Bites dot fm slash live and there's info about it there. Why don't you kick us off, Michael, with the first topic. Let's talk. Let's I'm going to do a lead in here to basically all of my things. Ready? I believe it was Friday. The folks behind Lightstar LITE Star is a Async framework for building APIs in Python. It's pretty interesting. Similar, but not the same as fast API. They kind of share some of the same Zen. Now I'm not ready to talk about Lightstar. This is not actually my thing. I will at some point probably. It's pretty popular 2.4 thousand stars. I'm just cool. But I'm like, huh, let me learn more about this. Like, let me see what this is built on. And so I started poking through what did I poke through? Not the requirements, but the poetry lock file and and project and all that stuff. And came across two projects that are not super well known, I think. And I kind of want to shine a light on them by way of finding them through Lightstar. So the first one I want to talk about is Async Timeout. And I know you have some stuff you want to talk about with context managers. And this kind of lines right up there. So this is an AsyncIO compatible, as in Async and await keywords, Timeout class. And it is itself a context manager. Not the only way you could possibly use it, I suppose. But it's a context manager. And the idea is you say Async with Timeout. And then whatever you do inside of that block, that context manager, that with block. If it's asynchronous and it takes longer than the timeout you specified, it will cancel it and raise an exception, say, this took too long. Maybe you're trying to talk to a database and you're not sure it's on. Or you're trying to call an API and you don't know, you don't want to wait more than two seconds for the API to respond. Or whatever it is you're after. That's what you do is you just say Async with Timeout. And then it manages all the nested AsyncIO calls. And if something goes wrong there, it just raises an exception and cancels it. That's really pretty cool. Isn't that cool? There are ways in which in Python 3.11, I believe it was added, where you can create a task group. And then you can do certain things. But I believe you got to pass. You got to use the task group itself to run the work. OK, so you're pretty sure that's how you do it. It's been a while since I thought about it. It'd be some task group dot, you know, create task. And you await it. Something along those lines, right? And there, you've got to be really explicit. Not just in the parts within that, but all the stuff that's doing Async and Await deep down in the guts. They all kind of got to know about this task group deal, I believe. I'm remembering it correctly. And this one, you don't have to do that, right? You just run Async stuff within this with block. And if it takes too long, that's it. So in the example here, it says we have an Await Enter. This is like all the work that's happening. I don't see why that has to be just one. It could be multiple things. Yeah. And it says if it executes faster than the timeout, it just runs as if nothing happened. Otherwise, the inner work is canceled internally by sending an AsyncIo dot canceled error into it. But from the outside, that's transformed into a timeout error that's raised outside the context manager scope. Pretty cool, huh? Yeah, that's handy. Yeah, there's another way you can specify. You can say timeout at, like now plus 1.5 seconds, if you'd rather than just saying 1.5 seconds. So if there's, you want to capture a time at some point, then later you want to say that time plus some bit of time. You can also access things like the expired property on the context manager, which tells you whether or not it was expired or whether it ran successfully inside the context manager. You can ask for the deadline so you know how long it takes. And you can upgrade the time as it runs. You're like, oh, this part took too long or under some circumstance, something happened. So we need to do more work. Like maybe we're checking the API if there's a user, but actually there's not. So we've got to create the new user and we've got to send them an email and that might take more time than we were in the sort of other scenario. So you can say shift by or shift to for time. So you can say, hey, we need to add a second to the timeout within this context manager. Interesting. Basically reschedule it. Yeah. Oh, that's pretty cool. Yeah. So that's one thing. And then there's one other bit in here. The wait for, right. It says, so this is useful when async I will wait for is not suitable, but it's also faster than wait for because it doesn't create a separate task that is also scheduled as async wait for itself does. So it's not totally unique functionality in Python, but it's a neat way to look at it. And I think this is a nice little library. Yeah. I like that. The interface too, it's pretty clean as well. Yeah. A good little API there because it's a context manager. Huh? Yeah. Well, let's, let's reorder my topics a little bit. Let's talk about context managers. I change your order. Sorry. That's all right. So Trey Hunter has written an article called Creating a Context Manager in Python. And we, it's as you've just described, a context manager is really the things that you use a with block with. And there's a whole bunch of them. Like there's a open, if you say with open and then a file name as file, then it, the automatic, the context manager automatically closes it afterwards. So really this article is about, this is pretty awesome, but how do we do it ourselves? And, and so he kind of walks through, he's got a bunch of a bunch of detail here, which is great. It's not too long of an article though. A useful one, which I thought that was an awesome good example is having a context manager that changed an environmental variable just with the with block. And then it goes back to the way it was before. And the code for this is just a, it's just a class with, it's not inheriting from anything. And the context manager class is a class that has a dunder init, dunder enter, and dunder exit functions. And then he talks about all the stuff you have to put in here. And then in your example before you said as like with the timer as CM or something so that you could access that to see, you know, values afterwards. So Trey talks about how, what is the, how do you get the as functionality to work? And really it's just, you have to return something. And then there's enter and exit functions. And there's, yeah. How do you deal with all of those? It's a great, it's just a little great article. I love using context managers and knowing how to, I think it's makes sense to practice a couple of these because knowing how to use one in the, in the context of your own code, there's frequently times where you have to do something and you know, you're going to have to clean up or something or there's some final thing that you have to do. You don't really want to have that littered all over your code, especially if you're doing a code, especially if there's multiple exit points or return points in a context manager is a great way to, to deal with that. I did want to shout out to PyTest a little bit. So the, the environmental variable part example is a great useful one for normal code. If you ever want to change the environment outside of testing, but if you're doing it in testing, I recommend making sure that you, I scrolled to the wrong spot. There's a monkey patch thing within PyTest. If you use fixtures, monkey patch, there is a set environment monkey patch portion. So within a test, that's how you do an environmental variable. But outside of a test, why not create your own context manager? Oh, you're muted. So the environment variable only exists while you're in the context block, right? That's cool. The with blog. Yeah. Or you're changing it. Like if you wanted to add a path, add something to the path, path or something. Sure. There's other ways to do the path, but let's say it's a, I don't know, some other windows environment variable or something. But yeah. Yeah. These things are so cool. So if you ever find yourself writing, try finally, and the finally part is unwinding something like it's clearing some variable or deleting a temporary file or closing a connection, that's a super good chance to be using a context manager instead. Cause you just say with the thing and then it goes, I'll give two examples that I think were really fun and that people might connect with. So prior to SQL alchemy 1.4, the session, which is the unit of work design pattern object in SQL alchemy, the idea of those are I start a session, I do some queries, updates, deletes, inserts more work. And then I commit all of that work in one shot. Like that thing didn't used to be a context manager. And so what was really awesome was I would create one, like a wrapper class that would say in this block, create a session, do all the work. And then if you look at the Dunder exit, it has whether or not there was an exception. And so my context manager, you could say when you create it, do you want to auto commit the transaction if it succeeds and auto roll it back if there's an error? And so you just say in the exit, is there an error? Roll back the session. If it's no errors, commit the session. And then you just, it's like beautiful, right? You don't have to juggle that. There's no try finally. There's awesome. Another one to put it in something sort of out of normal scope, maybe for people like the database one might be something you think of is colors. Yeah. Colorama. So if you're using something like Colorama where you're like, I want to change the color of the text for this block, right? So you, there's all sorts of colors and cool stuff. It's like a lightweight version of rich, but just for colors, you can do things like rent foreground dot red, and it'll do some sort of every bit of text that comes after that will be red or whatever. So you can create a context block that is like a color block of output. And then there's a reset all style that reset all you can do. So you just, in the open, you pass in the new color settings, you do all your print statements and whatever deep down. And then on the exit, you just say print style that reset all of out of Colorama and it's it's undone. Like the color vanishes or you capture what it is and then you reset it to the way it was before or something along those lines. But anyway, this is, I really like this, that kind of stuff, right? People maybe don't think about color as a context manager, but But it kind of is because you always have to do the thing afterwards. You always have to do the reset. Yes, and put it back. It's so annoying. Yeah. Anything where you have to put it back. You need other data structures that you may have like dirty, you've got queues sitting around that you want to clean up afterwards. Those are great for context managers. Absolutely. And then the screener notices that and points out that there's also concept context lib for making them. And I'm glad he brought that up. I was going to bring that up. Context lib is great, especially for quickly and doing context managers. But I think it's in and maybe the documentation is pretty good. You can do a decorator context manager and then you can use a yield for it. But I really like the notion of I guess you should understand both. I think people should understand how to write them with just Dunder methods and how to write them with the context manager and context lib. I think both are useful. But to mentally understand how the enter exit, all that stuff works, I think is important. So thanks, Brian. Yes. And let's tie the thing that I opened with and this one a little bit tighter together. Brian, there's an A enter and an A exit for async with blocks, right? So if you want an asynchronous enabled version, you just create an async, async def, A enter, then async def, A exit. And now you can do async and await stuff in your context manager, which is sort of the async equivalent of the enter and exit. And the context lib also has these async context manager options. A enter and A exit. Cool. Yeah, exactly. Very nice. Very nice. And let's go to the next one, huh? Yeah. So server sent events. Let's talk about server sent events. Server sent events, people probably, well, they certainly know what a request response is for the web because we do that in our browsers all the time. I enter a URL, the page comes back, I click a button, it does another request, it pulls back a page, maybe I submit a form, it posts it, and then it pulls back a page, right? Like that's traditional web interchange. But that is a stateless kind of one time and who knows what happens after that sort of experience for the web. And so there were a bunch of different styles of like, what if the web server and the client could talk to each other type of thing, right? In the early days, this is what's called long polling. This works, but it is bad on your server for what you do is you make a request and the server doesn't respond right away. It just says this request is going to time out in five minutes and then it'll wait. And if it has any events to send during that time, it'll respond and then you start another long polled event cycle, right? But the problem is you've got to, for everything that might be interested, you've got an open socket just waiting. Like in the process that requests queue sort of thing, it's not great. And then web sockets were added and web sockets are cool because they create this connection that is bi-directional, like a binary bi-directional socket channel from the web server to the client, which is cool. Not great for IOT things, mobile devices are not necessarily super good for web sockets. It's kind of heavyweight. It's like a very sort of complex, like we're going to be able to have a client talk to the server, but also the server, the client, they can respond to each other. So a lighter weight, simpler version of that would be server sent events. Okay. Okay. So what server sent events do is it's the same idea. Like I want to have the server without the client's interaction send messages to the client so I could create like a dashboard or something, right? The difference with server sent events is it's not bi-directional. Only the server can send information to the client, but often for like dashboard type things, that's all you want. Like I want to pull up a bunch of pieces of information and if any of them change, let the server notify me, right? Oh yeah. I want to, I want to create a page that shows the position of all the cars and F1, their last pit stop, their tires, like all of that stuff. And like if any of them change, I want the server to be able to let the browser know, but there's no reason the browser needs to like make a change, right? It's like, it's a watching, right? So if you have this watching scenario, server sent events are like a simpler, more lightweight, awesome way to do this. Okay. We all know what SSE, server sent events are. Okay. So if you want that in Python, there's this cool library, which is not super well known, but is cool is HTTP X. So HTTP X is kind of like requests sort of maybe the modern day version of requests because it has a really great async and await story going on. So there's this extension called HTTP X dash SSE for consuming server sent events with HTTP X. Oh, okay. Yeah. So if you want to be a client to one of these things in Python to some server that's sending out these notifications and these, these updates, well, HTTP X is an awesome way to do it because you can do async and await. So just a great client in general. And then here you plug this in and it has a really, really clean API to do it. So what you do is you would get the connect SSE out of it. And you just with HTTP X, you just create a client and then you say, connect the SSE to that client to some place gives you an event source. And then you just iterate, just say for thing and event, and it just blocks until the server sends you an event. And it'll think raise an exception if the socket's closed is what happens. So you just like loop over the events that the servers sending you when they happen. Okay. Cool. Isn't that cool? So yeah, so you could like in my F1 example, you could subscribe to the changes of the race and when anything happens, you would get like, there's a new tire event and here's the data about it and the ID of the event session and all those different things just streaming to you. And it's like literally five lines of code, sorry, six lines of code with the import statement. So what does it look like on the server then? I guess that's not what this, this it's not your problem. However, they do say you can, you can create a server, sorry, a starlet server here and they have below an example you can use. So it's cool. They've got a Python example for both ends. Yeah. So what, what you do on the server is you create an async function and here's a async function that just yields bits of just a series of numbers. It's kind of like a really cheesy example, but it, it sleeps for about an async second. It's like a New York second, like a New York minute, but one sixtieth of it and it doesn't block stuff. So you for an async second, you sleep and then it yields the data, right? And then you can just create one of these event source responses, which comes out of the starlet SSC, which is not related to this, I believe, but it's like kind of the server implementation and then you just set that as an endpoint. So in order to do that, they just connect to that and then they just get these, these numbers just streaming back every second. That's pretty cool. Yeah. I mean, all of this, like if I, if I hit con command minus one time, all of the, both the server and the client fit on one screen of code. Yeah. Yeah. That's pretty neat. What else do I have to say about it? It has an async way to call it and a synchronous way to call it because that's HTTPS is style. It shows how to do it with the async. Here's your async with block. I mean, it's full of context managers this episode and it shows you all the different things that you can do. It talks about how you to handle reconnects and you know, all of these little projects and all these things we're talking about are, um, there's sort of a breadcrumbs through the trail of Python. So it says, look, if there's an error, what you might do about that. Like if you disconnect, you might want to just let it be disconnected or you might want to try to reconnect or who knows, right? What you need to do is not really known by this library. So it just says, they're just going to get an exception, but it does provide a way to resume by holding onto the last event ID. So you can say like, Hey, you know, that generator you were sending me before, like let's keep doing that, which is kind of cool. And he'll just pick up, but here's the breadcrumbs. It says, here's how you might achieve this using stamina. And it has the operations here and it says on HTTPS gives a decorator says at retry on HTTPS dot reader. And then it goes how to redo it again and how often. So stamina is a project by Henik that allows you to do, um, asynchronous retries and all sorts of cool stuff. So maybe something fun to have. We talked about stamina before. I don't believe we have, I don't think we have left. I don't remember it either. But it's pretty cool anyway. Yeah. There's a lot of cool stuff in here, right? Yeah. And yeah, so people can go and check this out, but here's the retrying version. You can see an example of that where it just automatically will continue to keep going. So pretty cool little library here. HTTPS dash S E it has 51 get up stars. I feel like it deserves more. So people can give it a look. Yeah. Well, speaking of cool projects, I'll pipe, um, cool projects in Python. You probably grab them from PIPI, right? Of course. Do a PIP install. And let's take a look, uh, at stamina for instance, in a lot of projects, one of the things you can do, you can go down and on the left-hand side, there's project description, release history, download files. Everybody has all of them have that, but then there's project links and these change, they're different on different projects. So stamina has got a change log and documentation and funding and source, and they all have like icons associated with it. So I don't know what we have, we go to sources, it goes to get hub looks like, uh, funding. It's a get hub sponsors. That's pretty cool. Documentation. I'm looking at the bottom of my screen. Documentation links to stamina.inic.me. Okay. Interesting. Uh, change log. Anyway, these links are great on projects. Let's take a look at, uh, but they're different. So a textual just as a homepage. Okay. So, uh, HTTP has changed log, uh, homepage documentation. Um, I test as a bunch also, also it has a tracker. That's kind of neat and Twitter. Yeah. So, um, how do you get these? Uh, so if you have a project, it's really helpful to put these in here. And so there's Daniel Roy Greenfield wrote a blog post or posts saying, high PI project URLs cheat sheet. So basically figured all this stuff out. It's in, it's not documented really anywhere except for here, but it's in the warehouse code and the warehouse is the software that runs by PI. And I'm not going to dig through this too much, but basically it's the, uh, trying to figure out what the name is, the name that you put on in for a link and then which icon to use if that's it. So there's a bunch of different icons that are available. And anyway, we don't need to look at that too much because Daniel made a cheat sheet for us. So, uh, he shows a handful of them on, on the, on his post. Um, also a link to where they all are. But then, uh, what it is is you've got project URLs in your PI project Tomo file and it just lists a bunch of them that you probably want possibly like homepage repository change log. Anyway, this is a really cool cheat sheet of, uh, things that you might want to use and what, what names to give them. So it's a name equals string with the URL and you know, all some of the names on the left can be anything, but if they're special things, you get an icon. So nice anyway, and there's even a mastodon now one now. So that's cool. Yay. The gaps to change the Twitter one Twitter. Oh, it's Twitter or X. Interesting. Yeah. I think how much math that's going to break. It has to be called X everywhere now. No more algebra for you. Yeah. What a dumpster fire. Okay. Um, yeah, Mike on the audience points out the icons are courtesy of font. Awesome. And indeed they are, if you're not familiar with thought, awesome, check that out. So like we could come over here and search for, wait for it. GitHub. And you get all these icons here. One of them is the one that shows up. I don't remember which one of these it would be, but, um, if you know, so it shows you the code that you need is just F a brands, a space F a dash GitHub for the icon there. But if for some reason you're like, what if there was a merge one? I want to merge, but there's no merge that's there like on your other project, right? Then there's, there's, I don't know how many icons are in font awesome, like 6,000, yeah, 6,444 in total. And maybe no, I take that back because there's new 12,000 new ones. So there's a, there's a lot, let's just say there's a lot here. Well, the top said 26,000. So there we go. Yeah. Awesome. Yeah. So, oh, there's a fire one. Oh, there's so many good ones. That'd be good one for Twitter now. By the way, if you go to Python bytes and you would be, I would be, you go to the bottom, like all these little icons, these are all fun. Awesome. Even the little heart about made in Portland. Ah, ah, is font awesome a free thing or do you got to pay for it? You know, yes and no. So font awesome is there's like, if you, if I search for GitHub again, you see that some say pro and some don't. Yeah. So the pro, the ones that don't say pro are free. The ones that say pro are pro. They cost like a hundred dollars a year subscription, but I have a, I bought a subscription to it and just canceled it because you got the icons you need. I got the icon. If I'm just locked at version six for a good long while, that's fine. Maybe someday I'll buy more, but yeah. So there you go. Nice. So yeah, that's, that's awesome, but it's cool how you are, how you pointed out Danny related that to the pie project. Tom, I had no idea that that's how this went together. That's cool. Nice. All right. All right. Well, I've got my screen up. I'm off to the next one. Huh? Yeah. I died. We're done with them. Are we? That was, I have no more items, no more items to cover other than extras. Okay. Well, I have a few couple extras. So I, a couple more people, more people, more people, more people on Python people. What did I want to say? Oh, just that, that I had some great feedback. So I love drawing, starting something new. It's good to provide feedback for people. And I got some wonderful feedback that the music that I stole from testing code is annoying on Python people because it's a completely different tone and fair enough. So I'm going to go through and rip out all the music, the intro music out of a Python people. So, and also the next episode is coming out this week. It'll be Bob builder boats from pie bites. It's a good episode. So should be out later this week. Do you have any extras? I do. I do. I do. I do have some cool announcements and some extras and all of those things. First of all, this is this achieve fusion with net energy game for the second time. So you know, the Holy grail of energy is fusion, not vision, right? Just squishing stuff together like the sun does and getting heavier, heavier particles and tons of energy with no waste, no negative waste really. I mean, there's output, but like helium or something, right? Oh no, we need more helium anyway. I don't know, Brian, if you knew, but there's a helium shortage and a crisis of helium potentially. We'll see that someday. Anyway, the big news is the folks over at the NIF repeated this big breakthrough that they had last year at the national ignition facility. So congrats to them. And why am I covering this year other than, Hey, it's kind of cool. Science is last year after that, or actually earlier this year, I had J. Sal Salman son on the show and we talked about all the Python that is behind that project at the NIF and how they use Python to help power up the whole Nash fusion breakthrough that they had. So very cool. If people want to learn more about that, they can listen to the episode 403 on talk by the enemy and just congrats to Jay and team again. That's very cool. Do they have a 1.21 gigawatt one yet? That would be good. Go back in time yet. No, no. But it, if you actually look, there's a video, uh, down there, this video demonstration. If you actually look at the project here, the, the machine that it goes through, this is like a room size, like a warehouse room size machine of lasers and coolers and mirrors and insane stuff that it goes through till it in, it hits like a dime size or small marble size piece somewhere. There's like an insane, there is. That's not exactly what you're asking for, but there is something insane on the other side of the devices. Yeah. We've got ways to get this into a car. Yeah. I mean, Marty McFly has got definitely wait to save his parents relationship. Okay. All right. All right. I have another bit of positive news. I think this is positive. This is a very positive news. Yeah. The other positive news is, you know, I've kind of knocked on, on Facebook and Google. I last time I think I was railing against Google and their, their DRM for websites and like their ongoing persistent premise that we must track and we target you. So how can we make the web better? Like no, no, that's not the assumption we need to start with. No it's not. Um, so I would, you know, I just wouldn't point out maybe like a little credit, a little credit to Facebook at this time, a little, maybe a positive shout out. So there's a bunch of rules that I think are off the target by here. And for example, um, there, there were a bunch of attempts and like in Spain, there was an attempt to say, um, if you're going to link to a news organization, you have to pay them. Okay. Like, wait a minute. So, so our, our big platform is sending you free traffic and to do that, we have to pay you, you know, because the newspapers are having a hard time and they're important, but maybe that's a little bit off. Probably the most outrageous of this category of them were somewhere in Europe. I can't remember if it was the EU in general or a particular company, a country rather, sorry. They were trying to make companies like Netflix and Google via because of YouTube pay for their broadband because people consume a lot of their content. So it uses a lot of their traffic. It's like, wait a minute, we're paying already to like get this to you. And then you're going to charge us to make you pay for our infrastructure. I don't know. I just, you're like, oh, no, no, no, that seems really odd to say like, you know, Netflix should pay for Europe's fiber because people watch Netflix. I don't know, that just, it seems super backwards to me. So okay, I'm going to be devil's advocate here. I think that, um, that if Netflix, for example, if Netflix is taking half the bandwidth or something like that, then all of the infrastructure costs, half of those costs are benefiting Netflix and they're profiting off of it. I think that's sort of legitimate. It depends on the scale, right? I think like, um, we are not taking a ton of bandwidth from Europe, so it would be weird for us to have to pay something. But if I'm taking a measurable percentage, that's probably maybe okay. The other side is like, I read Google news still, even though I'm not a huge fan of Google, but I read Google news. There's a lot of times where that's enough. I'm like, is there anything important happening? I'm just reading the headlines. I'm not clicking on the link. And that, that benefit then for Google wouldn't be there if the newspapers weren't there. So I would say some money going to the newspapers that are providing those headlines. I think that's fair. So I certainly hear what you're saying with the news on that. Um, we still haven't got to the top. I get away. Okay. I know, no, but I totally hear you. I think with the bandwidth, like the customers decide, like no one's Netflix isn't projecting stuff onto the people in Europe and they're receiving it out of the band. They seek it out. Right. So I don't know. I feel like, but yeah, we can, yeah, that's, I, I appreciate the devil's advocate. Yeah. That was the thing. So here's the news though. Facebook and more generally meta is protesting a new Canadian law, obliging it to pay for news that if, so if my mom shares an article, say my mom was Canadian and she shared an article to some, um, some news thing, uh, the Canadian post or whatever, then on Facebook, then Facebook would have to pay the Canadian post cause my mom put it there. So they're protesting it by no longer having news in Canada. News doesn't exist in Canada now on Facebook or yeah. So my mom tried to post it. They were just like, that can't be posted. Oh, well that's weird. Isn't that weird? So I actually kind of agree with you on the Google news bit, like where a good chunk of it is there and it becomes almost a reader type service, but like Facebook doesn't do that. It just says, well, here's the, here's the thumbnail and you could click on it, but also there's a lot of, a lot of anger below it, but get their news from people sharing it on Facebook. They follow, do they click it? That's the goal. Do they, do they, do they often not, uh, possibly. And is it free? Is the, is the bandwidth if, if like, if I share it with a million people, um, and they don't click on it, does it cost the news paper? Possibly they might be drawing it for the headline and the image and all that stuff. They might. Yeah. They probably cash it, but they might, might not. So I'll leave, I'll put this out there for people to have their own opinions. Um, but I, I think this is something that Facebook should stand up to and just me not speaking for Brian. Well done Facebook. I don't think, I don't think this makes any sense. Like they're protesting this law that makes them pay if my mom or Canadian and put news into her feed. Yeah. And I'll just say way to go Canada. I like it. Awesome. All right. Cool. That's it for all the items I got. You covered yours, right? Yes, I did. So let's do something funny before we get into fisticuffs. So before, no, never. So, well, you want to talk about fisticuffs. So let's see the joke. So this joke makes fun of a particular language. The point is not to make fun of that language. It's to make fun of AI. Okay. So people who are, want to support the AI, they can send me their angry messages. People who are fans of the language I'm about to show you, please don't. Not about that. Okay. So if you were working with a GitHub copilot, you know, a lot of times it tries to auto suggest stuff for you, right? That didn't zoom that. It tries to auto suggest stuff for you. Yeah. And so if you say like, this is C sharp, people know I've done C sharp before. I like it at all. So not make fun of it, but it's just a slash slash day. And then there's an auto complete statement that the copilot is trying to write. What does it say? Right? Day one of C sharp and I already hate it. So like how many people have written this in their like online journals or something? Yes, exactly. What in the world is going on here? So there's some, there's some fun comments, but they're not too great down here. But I just, I just thought like, you know, this, this weirdo, weirdo, auto complete, like we're going to get into this where this kind of stuff happens all the time. Right? This is kind of the Google suggest, you know, let's see if I can get it to work here. We go to Google and type American Americans are, you know, what does it say? Right. Struggling entitled. Yeah. Like C sharp developers are, and then it'll give you like a list or let's do it with Python. Right. I thought I thought, right. Who are the Python? Why are they paid so much? Who hired these people? It's sort of right. So this is the AI equivalent, but it's going to be right where you work all the time. That's funny. And, and Joe out there says, I wonder what it says for day one of Python. I have no idea, but somebody had copilot installed. They should let us know. And what maybe we'll point it out next time. Yeah. Interesting. I haven't turned it on, but no, I haven't either. All right. All right. Well, thanks. I'm sorry, like the usage numbers are kind of off the chart. Well, so yeah, I'll just say one of the people used to not like maintaining software written by others and they mostly like writing green field code, but with copilot, you don't have to write your first draft. You can, you can just become a permanent maintainer of software. Exactly. I wrote the bullet points and now I maintain what the AI wrote. Fantastic. Exactly. Hope you understand it. Yeah, exactly. Sorry. But anyway, well, thanks a lot for a great day again, or a great episode. Absolutely. Thank you. See y'all later."}, "podcast_summary": "Thank you for listening to Python Bites. You can find the show notes, links to the articles discussed, and other resources at pythonbytes.fm. If you enjoyed the show, please leave us a review on Apple Podcasts or Spotify. If you'd like to support the show, you can do so on Patreon at patreon.com/pythonbytes. And if you're interested in learning more about Python, be sure to check out Michael's other podcast, Talk Python to Me, at talkpython.fm. Thanks so much for listening. We'll see you next time.", "podcast_guest": "Async Timeout", "podcast_highlights": "Thank you and goodbye!"}